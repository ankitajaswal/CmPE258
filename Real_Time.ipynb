{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM1FFzblZcejh8FdkrqR1yb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Use this script on local machine to run demo\n","\n","\n","1.   Uses MTCNN for face detection\n","2.   Uses HSEmotion 'enet_b0_best_afew' EfficientNet model trained on AFEW dataset.\n","\n","- Author: Ankita Jaswal"],"metadata":{"id":"ce9-eJIhkmxG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8pzS0nmebDLI"},"outputs":[],"source":["import os\n","\n","# dependencies\n","os.system('pip install hsemotion')\n","os.system('pip install mtcnn')\n","\n","import cv2\n","import numpy as np\n","from mtcnn import MTCNN\n","from hsemotion.facial_emotions import HSEmotionRecognizer\n","\n","# Initialize the HSEmotion recognizer\n","model_name = 'enet_b0_8_best_afew'\n","fer = HSEmotionRecognizer(model_name=model_name, device='cpu')  # 'cpu' or 'cuda'\n","\n","# Initialize the face detector\n","detector = MTCNN()\n","\n","# Start the webcam feed\n","cap = cv2.VideoCapture(0)\n","\n","while True:\n","    # Capture frame-by-frame\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # Convert the captured frame to RGB\n","    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","    # Detect faces in the image\n","    detections = detector.detect_faces(frame_rgb)\n","    for detection in detections:\n","        x, y, width, height = detection['box']\n","        face_img = frame_rgb[y:y+height, x:x+width]\n","\n","        # Predict emotion\n","        emotion_pred, scores = fer.predict_emotions(face_img, logits=True)\n","        maxindex = np.argmax(scores)\n","        emotion_label = fer.idx_to_class[maxindex]\n","\n","        # Draw the detected face and write the emotion\n","        cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 2)\n","        cv2.putText(frame, emotion_label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n","\n","    # Display the resulting frame\n","    cv2.imshow('Video', frame)\n","\n","    # Check if window closed\n","    if cv2.getWindowProperty('Video', cv2.WND_PROP_VISIBLE) < 1:\n","        break\n","\n","    # Exit upon pressing q key\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","# Release the capture and close windows\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","source":["# Now take some screenshots and plot the results"],"metadata":{"id":"1hRmvxmOjZRu"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import os\n","\n","# Directory of results\n","image_directory = 'path_to_saved_images_directory'\n","\n","# Create a figure\n","plt.figure(figsize=(10, 10))\n","\n","# Iterate over the files in the directory\n","for i, filename in enumerate(os.listdir(image_directory)):\n","    if filename.endswith(\".jpg\") or filename.endswith(\".png\", \".jpg\", \".jpeg\"):  # Add other file types if needed\n","        image_path = os.path.join(image_directory, filename)\n","        img = mpimg.imread(image_path)\n","        plt.subplot(5, 5, i+1)  # Adjust the grid size as needed\n","        plt.imshow(img)\n","        plt.axis('off')\n","\n","plt.show()\n"],"metadata":{"id":"WYyyX3r4jefq"},"execution_count":null,"outputs":[]}]}